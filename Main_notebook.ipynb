{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "YOLOv8 pretrained Detect models, includes YOLOv8n, YOLOv8s, YOLOv8m, YOLOv8l, and YOLOv8x, etc are pretrained on the COCO dataset."
      ],
      "metadata": {
        "id": "y6D74vEcPC3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "uF8xQTOTdN1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_nlp\n",
        "!pip install keras-cv\n",
        "!pip install roboflow\n",
        "!pip install supervision\n",
        "!pip install yolov8\n",
        "!pip install supervisely\n",
        "!pip uninstall pydantic -y\n",
        "!pip install pydantic==2.5.0\n",
        "!pip install Roboflow"
      ],
      "metadata": {
        "id": "wENl8q65iwO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import keras_cv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import xml.etree.ElementTree as ET\n",
        "from keras_cv import bounding_box\n",
        "from keras_cv import visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn import metrics\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Iu77s17zyLls"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "4lY3oB3uiqDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Link to Kaggle and Load Data\n",
        "!mkdir /root/.kaggle\n",
        "!cp /content/kaggle.json /root/.kaggle/kaggle.json\n",
        "\n",
        "# Copy the API command from Kaggle, should be the following format\n",
        "# !kaggle datasets download -d crowdflower/twitter-airline-sentiment -p ./airline_tweets\n",
        "\n",
        "!kaggle datasets download -d snehilsanyal/construction-site-safety-image-dataset-roboflow -p ./construction_site\n",
        "!unzip /content/construction_site/construction-site-safety-image-dataset-roboflow.zip"
      ],
      "metadata": {
        "id": "lgBvl9qR9NYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data from Roboflow with YOLOv8 format: https://universe.roboflow.com/roboflow-universe-projects/construction-site-safety/dataset/30#\n",
        "\n",
        "Details of data set can be found in report:\n",
        "The data file downloaded has already been split into train, validation, and test set.\n",
        "\n",
        "Number of classes: 10\n",
        "Because this task is specifically for construction site, we labels 10 categories that are of interest: Class Map {0: 'Hardhat', 1: 'Mask', 2: 'NO-Hardhat', 3: 'NO-Mask', 4: 'NO-Safety Vest', 5: 'Person', 6: 'Safety Cone', 7: 'Safety Vest', 8: 'machinery', 9: 'vehicle'}\n",
        "\n",
        "Label Annotation: YoloV8 format\n",
        "\n",
        "NOTE: NEED TO GENERATE AN API KEY ON ROBOFLOW AND PUT IT WHERE rf = Roboflow(api_key=\"YOUR PRIVATE KEY\")"
      ],
      "metadata": {
        "id": "XrYkaavq2VHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Citation: @misc{ construction-site-safety_dataset,\n",
        "    title = { Construction Site Safety Dataset },\n",
        "    type = { Open Source Dataset },\n",
        "    author = { Roboflow Universe Projects },\n",
        "    howpublished = { \\url{ https://universe.roboflow.com/roboflow-universe-projects/construction-site-safety } },\n",
        "    url = { https://universe.roboflow.com/roboflow-universe-projects/construction-site-safety },\n",
        "    journal = { Roboflow Universe },\n",
        "    publisher = { Roboflow },\n",
        "    year = { 2023 },\n",
        "    month = { feb }\n",
        "}\n"
      ],
      "metadata": {
        "id": "yF-pj15G8abK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"#####\")\n",
        "############# Need to change it to your private API key for ROBO\n",
        "project = rf.workspace(\"roboflow-universe-projects\").project(\"construction-site-safety\")\n",
        "version = project.version(28)\n",
        "dataset = version.download(\"yolov8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0NIz0L-2Qat",
        "outputId": "463723dd-210e-4b4c-f063-12d4efed3463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics==8.0.196 is required but found version=8.1.25, to fix: `pip install ultralytics==8.0.196`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Construction-Site-Safety-28 to yolov8:: 100%|██████████| 153903/153903 [00:09<00:00, 16117.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Construction-Site-Safety-28 in yolov8:: 100%|██████████| 5614/5614 [00:00<00:00, 6800.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install PyYAML\n",
        "import yaml\n",
        "\n",
        "with open(\"/content/Construction-Site-Safety-28/data.yaml\", \"r\") as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "data_config[\"train\"] = \"/content/Construction-Site-Safety-28/train/images\"\n",
        "data_config[\"val\"] = \"/content/Construction-Site-Safety-28/valid/images\"\n",
        "\n",
        "with open(\"/content/Construction-Site-Safety-28/data.yaml\", \"w\") as f:\n",
        "    yaml.dump(data_config, f)\n",
        "\n",
        "data_yaml = \"/content/Construction-Site-Safety-28/data.yaml\"\n"
      ],
      "metadata": {
        "id": "YRyrYsDqKEfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning pretrained models"
      ],
      "metadata": {
        "id": "5WGE34B2w44C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuning YOLOv8n, YOLOv8s, YOLOv8m, YOLOv8l, and YOLOv8x\n",
        "\n",
        "The most typical pretrained models for YOLOv8 object detection models are YOLOv8n, YOLOv8s, YOLOv8m, YOLOv8l, and YOLOv8x, but here we pick three to test on to see. The differ the number of Layers, width of the Network, resolution of Input Images, and etc. So in general, they differ in complexity in their architectures, with YOLOv8x being the most complex, and YOLOv8n being the most simple and fastest one.\n",
        "\n",
        "imgsz=640: This sets the image size to 640 pixels. In object detection models like YOLO, the input image is often resized to a standard size, in this case, 640x640 pixels.\n",
        "\n",
        "half=False: This is specifying the precision of the calculations. If set to True, it might use half-precision (16-bit) floating-point numbers to speed up model inference, sacrificing a bit of accuracy for speed. 'False' means it's likely using full precision (32-bit)."
      ],
      "metadata": {
        "id": "pDqdSB7wA0TL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tune yolov8n"
      ],
      "metadata": {
        "id": "7vIn0WnLMHi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots will be saved to content/runs/detect/train file, can check there"
      ],
      "metadata": {
        "id": "4J11hgog3grz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build a new model from YAML\n",
        "model_fine_n = YOLO('yolov8n.yaml')\n",
        "\n",
        "# load a pretrained model\n",
        "model_fine_n = YOLO('yolov8n.pt')\n",
        "\n",
        "# build from YAML and transfer weights\n",
        "model_fine_n = YOLO('yolov8n.yaml').load('yolov8n.pt')\n",
        "\n",
        "# Train the model\n",
        "results = model_fine_n.train(data= data_yaml, epochs= 40, imgsz=640, patience = 3, plots=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVl-nBdEDMSa",
        "outputId": "06ae3be4-8aff-48d9-c18c-e3259f910610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 355/355 items from pretrained weights\n",
            "Ultralytics YOLOv8.1.25 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/Construction-Site-Safety-28/data.yaml, epochs=40, time=None, patience=3, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
            "YOLOv8n summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Construction-Site-Safety-28/train/labels.cache... 2605 images, 6 backgrounds, 0 corrupt: 100%|██████████| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/Construction-Site-Safety-28/train/images/004720_jpg.rf.afc486560a4004c7cfd67910af31a29c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/Construction-Site-Safety-28/train/images/construction-813-_jpg.rf.b085952261fd98f2e76b8065de149b5f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Construction-Site-Safety-28/valid/labels.cache... 114 images, 10 backgrounds, 0 corrupt: 100%|██████████| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/40      3.46G      1.385      2.775      1.488        263        640: 100%|██████████| 163/163 [00:21<00:00,  7.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.497      0.334      0.334      0.154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/40      3.19G      1.292      1.843      1.443        228        640: 100%|██████████| 163/163 [00:15<00:00, 10.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.626      0.459       0.49      0.234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/40      3.32G      1.244      1.639      1.404        256        640: 100%|██████████| 163/163 [00:15<00:00, 10.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.608      0.449      0.453      0.208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/40      2.86G      1.233      1.566      1.386        258        640: 100%|██████████| 163/163 [00:15<00:00, 10.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.642      0.454      0.481      0.197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/40      3.07G      1.207      1.506      1.369        386        640: 100%|██████████| 163/163 [00:15<00:00, 10.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.659      0.535      0.571      0.258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/40      3.36G      1.182      1.427      1.338        310        640: 100%|██████████| 163/163 [00:15<00:00, 10.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.729       0.49      0.571      0.254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/40      3.23G      1.164      1.373      1.331        342        640: 100%|██████████| 163/163 [00:15<00:00, 10.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.749      0.522      0.588      0.278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/40      3.43G      1.136      1.329       1.31        294        640: 100%|██████████| 163/163 [00:15<00:00, 10.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.741      0.564      0.628      0.299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/40      3.55G      1.144      1.287      1.305        370        640: 100%|██████████| 163/163 [00:15<00:00, 10.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.719      0.576      0.624      0.317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/40      3.21G      1.108      1.251      1.291        320        640: 100%|██████████| 163/163 [00:15<00:00, 10.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.802      0.559      0.631      0.326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/40      3.23G      1.096      1.211      1.276        236        640: 100%|██████████| 163/163 [00:15<00:00, 10.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.723      0.564      0.622      0.325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/40      3.48G      1.077      1.177      1.263        265        640: 100%|██████████| 163/163 [00:15<00:00, 10.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.746      0.613      0.652      0.327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/40      3.85G      1.075      1.154      1.259        213        640: 100%|██████████| 163/163 [00:14<00:00, 10.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.748      0.624      0.663      0.334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/40      3.26G      1.072      1.138      1.256        190        640: 100%|██████████| 163/163 [00:15<00:00, 10.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.829      0.595      0.675      0.337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/40      3.31G      1.051      1.115       1.25        432        640: 100%|██████████| 163/163 [00:15<00:00, 10.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697       0.74       0.59      0.663      0.344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/40       3.6G      1.055      1.087      1.241        323        640: 100%|██████████| 163/163 [00:15<00:00, 10.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.793      0.628      0.701      0.386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/40      2.84G      1.027       1.07       1.23        295        640: 100%|██████████| 163/163 [00:15<00:00, 10.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.849      0.578      0.671      0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/40      3.82G      1.034      1.046      1.224        424        640: 100%|██████████| 163/163 [00:15<00:00, 10.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.836      0.625      0.697      0.377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/40      3.21G      1.019      1.032      1.225        344        640: 100%|██████████| 163/163 [00:15<00:00, 10.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.801      0.644      0.701      0.364\n",
            "Stopping training early as no improvement observed in last 3 epochs. Best results observed at epoch 16, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "19 epochs completed in 0.088 hours.\n",
            "Optimizer stripped from runs/detect/train4/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train4/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train4/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.25 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.803      0.628      0.701      0.387\n",
            "               Hardhat        114         79      0.916      0.687      0.808      0.495\n",
            "                  Mask        114         21          1      0.738      0.808      0.508\n",
            "            NO-Hardhat        114         69      0.839      0.507      0.605      0.237\n",
            "               NO-Mask        114         74      0.699      0.459      0.524      0.221\n",
            "        NO-Safety Vest        114        106      0.681      0.491      0.615      0.316\n",
            "                Person        114        166      0.804      0.669       0.77      0.415\n",
            "           Safety Cone        114         44      0.835      0.841       0.85      0.464\n",
            "           Safety Vest        114         41       0.86      0.747      0.805      0.456\n",
            "             machinery        114         55      0.831      0.709      0.781       0.45\n",
            "               vehicle        114         42      0.561      0.429      0.449      0.304\n",
            "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### get the test set performance"
      ],
      "metadata": {
        "id": "oqxh3inq6SaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changed the file name in order to use the validation function to find out test accurac\n",
        "# test changes to valid\n",
        "# valid change to valid1\n",
        "old_dir_path = '/content/Construction-Site-Safety-28/valid'\n",
        "new_dir_path = '/content/Construction-Site-Safety-28/valid1'\n",
        "\n",
        "# Rename the directory\n",
        "os.rename(old_dir_path, new_dir_path)\n",
        "\n",
        "old_dir_path_test = '/content/Construction-Site-Safety-28/test'\n",
        "new_dir_path_test = '/content/Construction-Site-Safety-28/valid'\n",
        "\n",
        "# Rename the directory\n",
        "os.rename(old_dir_path_test, new_dir_path_test)"
      ],
      "metadata": {
        "id": "JTruzgAnmYGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fine_n.val(data='/content/Construction-Site-Safety-28/data.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwccAeL-hm1e",
        "outputId": "c32ed9b3-19a2-423a-b63e-2f420d383508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.25 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Construction-Site-Safety-28/valid/labels... 82 images, 8 backgrounds, 0 corrupt: 100%|██████████| 82/82 [00:00<00:00, 1374.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Construction-Site-Safety-28/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82        760       0.78      0.602      0.661      0.349\n",
            "               Hardhat         82        110      0.968      0.727      0.867      0.501\n",
            "                  Mask         82         28      0.973      0.679      0.749      0.426\n",
            "            NO-Hardhat         82         41      0.607      0.439      0.447      0.161\n",
            "               NO-Mask         82         79      0.634      0.506      0.555      0.228\n",
            "        NO-Safety Vest         82         90      0.786      0.613      0.643      0.299\n",
            "                Person         82        174      0.787      0.701      0.747      0.414\n",
            "           Safety Cone         82         92      0.758      0.359      0.434      0.172\n",
            "           Safety Vest         82         61      0.856      0.779      0.859      0.485\n",
            "             machinery         82         44      0.799      0.724      0.787      0.496\n",
            "               vehicle         82         41      0.627      0.488      0.517      0.308\n",
            "Speed: 0.2ms preprocess, 28.2ms inference, 0.0ms loss, 34.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train42\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7ab9660d5d80>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0019335,  0.00096673,           0],\n",
              "       [          1,           1,           1, ...,  0.00039375,  0.00019688,           0],\n",
              "       [          1,           1,           1, ...,  0.00011421,  5.7103e-05,           0],\n",
              "       ...,\n",
              "       [          1,           1,           1, ...,   0.0016717,  0.00083585,           0],\n",
              "       [          1,           1,           1, ...,   0.0014568,  0.00072842,           0],\n",
              "       [          1,           1,           1, ...,  0.00028501,   0.0001425,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.16013,     0.16013,     0.21038, ...,           0,           0,           0],\n",
              "       [       0.08,        0.08,     0.13961, ...,           0,           0,           0],\n",
              "       [   0.042955,    0.042992,    0.069001, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [    0.10345,     0.10345,     0.13361, ...,           0,           0,           0],\n",
              "       [   0.032526,    0.032542,    0.053038, ...,           0,           0,           0],\n",
              "       [   0.053702,    0.053711,    0.085501, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.087796,    0.087796,     0.11895, ...,           1,           1,           1],\n",
              "       [   0.042146,    0.042146,    0.076612, ...,           1,           1,           1],\n",
              "       [   0.022262,    0.022282,     0.03657, ...,           1,           1,           1],\n",
              "       ...,\n",
              "       [   0.054755,    0.054755,    0.071949, ...,           1,           1,           1],\n",
              "       [   0.016538,    0.016546,    0.027259, ...,           1,           1,           1],\n",
              "       [   0.027778,    0.027782,    0.045149, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.90909,     0.90909,     0.90909, ...,           0,           0,           0],\n",
              "       [    0.78571,     0.78571,     0.78571, ...,           0,           0,           0],\n",
              "       [    0.60976,     0.60976,     0.60976, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [    0.93443,     0.93443,     0.93443, ...,           0,           0,           0],\n",
              "       [    0.97727,     0.97727,     0.97727, ...,           0,           0,           0],\n",
              "       [    0.80488,     0.80488,     0.80488, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.3802604509712177\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.50125,     0.42595,     0.16126,     0.22822,     0.29937,     0.41415,     0.17205,      0.4851,     0.49609,     0.30767])\n",
              "names: {0: 'Hardhat', 1: 'Mask', 2: 'NO-Hardhat', 3: 'NO-Mask', 4: 'NO-Safety Vest', 5: 'Person', 6: 'Safety Cone', 7: 'Safety Vest', 8: 'machinery', 9: 'vehicle'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.7795664044921249, 'metrics/recall(B)': 0.6015442872894006, 'metrics/mAP50(B)': 0.660614368567444, 'metrics/mAP50-95(B)': 0.3491100156827481, 'fitness': 0.3802604509712177}\n",
              "save_dir: PosixPath('runs/detect/train42')\n",
              "speed: {'preprocess': 0.15994397605337748, 'inference': 28.19547711349115, 'loss': 0.0008344650268554688, 'postprocess': 34.61226021371237}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the path back\n",
        "old_dir_path = '/content/Construction-Site-Safety-28/valid'\n",
        "new_dir_path = '/content/Construction-Site-Safety-28/test'\n",
        "\n",
        "# Rename the directory\n",
        "os.rename(old_dir_path, new_dir_path)\n",
        "\n",
        "old_dir_path_test = '/content/Construction-Site-Safety-28/valid1'\n",
        "new_dir_path_test = '/content/Construction-Site-Safety-28/valid'\n",
        "\n",
        "# Rename the directory\n",
        "os.rename(old_dir_path_test, new_dir_path_test)\n",
        "Input_path = \"/content/Construction-Site-Safety-28/test/images/000005_jpg.rf.96e9379ccae638140c4a90fc4b700a2b.jpg\""
      ],
      "metadata": {
        "id": "yH68xCxzJkEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = model_fine_n.predict(source=Input_path, save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo5W28G-JuRi",
        "outputId": "3ca75d20-0ae2-412e-fc71-fe5aaae6658d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/Construction-Site-Safety-28/test/images/000005_jpg.rf.96e9379ccae638140c4a90fc4b700a2b.jpg: 640x640 2 Hardhats, 1 NO-Hardhat, 3 NO-Masks, 4 Persons, 14.9ms\n",
            "Speed: 3.3ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train44\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### get the image annotation by our model"
      ],
      "metadata": {
        "id": "bUwOZXfXsPx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = \"/content/Construction-Site-Safety-28/test/images\"\n",
        "test_path_annotate = \"/content/Construction-Site-Safety-28/test/labels\"\n",
        "\n",
        "results = model_fine_n.predict(source=test_path, save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc5cUiy3aIN9",
        "outputId": "48035bc9-6067-4bf6-eb79-c0aceea2ee37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/82 /content/Construction-Site-Safety-28/test/images/-4405-_png_jpg.rf.82b5c10b2acd1cfaa24259ada8e599fe.jpg: 640x640 1 Person, 1 machinery, 12.2ms\n",
            "image 2/82 /content/Construction-Site-Safety-28/test/images/000005_jpg.rf.96e9379ccae638140c4a90fc4b700a2b.jpg: 640x640 1 Hardhat, 1 NO-Hardhat, 8.4ms\n",
            "image 3/82 /content/Construction-Site-Safety-28/test/images/002551_jpg.rf.ce4b9f934161faa72c80dc6898d37b2d.jpg: 640x640 1 Hardhat, 3 Persons, 2 Safety Vests, 1 machinery, 8.6ms\n",
            "image 4/82 /content/Construction-Site-Safety-28/test/images/003357_jpg.rf.9867f91e88089bb68dc95947d5116d14.jpg: 640x640 1 Person, 1 Safety Cone, 1 machinery, 8.4ms\n",
            "image 5/82 /content/Construction-Site-Safety-28/test/images/004063_jpg.rf.1b7cdc4035bcb24ef69b8798b444053e.jpg: 640x640 5 Hardhats, 1 NO-Safety Vest, 6 Persons, 1 Safety Vest, 1 machinery, 8.3ms\n",
            "image 6/82 /content/Construction-Site-Safety-28/test/images/004763_jpg.rf.46484e6ca73caeaa9de45822cf1085a9.jpg: 640x640 2 Hardhats, 1 NO-Hardhat, 3 NO-Masks, 1 Person, 8.4ms\n",
            "image 7/82 /content/Construction-Site-Safety-28/test/images/006463_jpg.rf.02f19082420ecc5537b9d59abbe6050c.jpg: 640x640 10 Hardhats, 1 NO-Hardhat, 19 NO-Masks, 1 NO-Safety Vest, 20 Persons, 8 Safety Vests, 8.4ms\n",
            "image 8/82 /content/Construction-Site-Safety-28/test/images/006672_jpg.rf.87d5978c486feb53177408cf00a0d87f.jpg: 640x640 6 Hardhats, 1 NO-Mask, 1 NO-Safety Vest, 8 Persons, 4 Safety Vests, 1 machinery, 2 vehicles, 8.7ms\n",
            "image 9/82 /content/Construction-Site-Safety-28/test/images/0_jpg.rf.2ff49f74309118f169e07aa12564df87.jpg: 640x640 1 NO-Mask, 2 Persons, 2 Safety Vests, 10 machinerys, 8.4ms\n",
            "image 10/82 /content/Construction-Site-Safety-28/test/images/2008_008320_jpg.rf.bd34011d46f82f9410d95f00e560b8ea.jpg: 640x640 2 NO-Masks, 1 NO-Safety Vest, 3 Persons, 1 machinery, 8.3ms\n",
            "image 11/82 /content/Construction-Site-Safety-28/test/images/2008_008519_jpg.rf.1798c8eed7de04399a0e7e297b4b4c9e.jpg: 640x640 6 Persons, 1 Safety Cone, 2 Safety Vests, 1 machinery, 8.3ms\n",
            "image 12/82 /content/Construction-Site-Safety-28/test/images/2009_000059_jpg.rf.50e8398a37eb33f33fd9f662feeea083.jpg: 640x640 1 Hardhat, 1 NO-Hardhat, 3 NO-Masks, 8.4ms\n",
            "image 13/82 /content/Construction-Site-Safety-28/test/images/2009_000496_jpg.rf.9a2d210fe0f5ea4b572aeb07e41ecbae.jpg: 640x640 3 Persons, 1 machinery, 8.3ms\n",
            "image 14/82 /content/Construction-Site-Safety-28/test/images/3e7e40981ddd4cdb055c7ffe4c2af5d8_jpg.rf.bac50dc18195e9aeb6f3a21782a3efcb.jpg: 640x640 (no detections), 8.3ms\n",
            "image 15/82 /content/Construction-Site-Safety-28/test/images/777_jpg.rf.92dc6945342410ced7ac93f3dfbff0c5.jpg: 640x640 (no detections), 18.0ms\n",
            "image 16/82 /content/Construction-Site-Safety-28/test/images/Bookstore_More_Merchandise_jpg.rf.7ab5add3e28ced74f9b316e794cc04d2.jpg: 640x640 2 machinerys, 8.4ms\n",
            "image 17/82 /content/Construction-Site-Safety-28/test/images/IMG_0871_MOV-12_jpg.rf.36858a9d51613f9a39b7855b54dfa098.jpg: 640x640 1 Person, 8.4ms\n",
            "image 18/82 /content/Construction-Site-Safety-28/test/images/IMG_0871_mp4-11_jpg.rf.432092b53ebeb84f4b9b27b40343c9aa.jpg: 640x640 1 Person, 8.4ms\n",
            "image 19/82 /content/Construction-Site-Safety-28/test/images/IMG_0871_mp4-23_jpg.rf.03f872b1ed87ad7fadc85e09475ad37a.jpg: 640x640 1 Mask, 1 Person, 8.3ms\n",
            "image 20/82 /content/Construction-Site-Safety-28/test/images/IMG_3100_mp4-12_jpg.rf.58849ca6a931c2cfe1b17fb4206d9d82.jpg: 640x640 1 NO-Hardhat, 8.3ms\n",
            "image 21/82 /content/Construction-Site-Safety-28/test/images/IMG_3100_mp4-9_jpg.rf.413ccf5fe4a7ee67f71e07c2c43b6756.jpg: 640x640 (no detections), 8.2ms\n",
            "image 22/82 /content/Construction-Site-Safety-28/test/images/IMG_3103_mp4-9_jpg.rf.b31bd2d816465a27aa1eb072f90bb5aa.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 Person, 8.7ms\n",
            "image 23/82 /content/Construction-Site-Safety-28/test/images/IMG_5846_jpg.rf.0b9984069116e2acd928568eb7a8e214.jpg: 640x640 25 Hardhats, 3 NO-Masks, 48 Persons, 32 Safety Vests, 1 machinery, 8.7ms\n",
            "image 24/82 /content/Construction-Site-Safety-28/test/images/Image36_jpg.rf.8704f3450f736cdd01a61dcee588f2c2.jpg: 640x640 6 Hardhats, 1 NO-Hardhat, 9 NO-Masks, 2 NO-Safety Vests, 10 Persons, 8.3ms\n",
            "image 25/82 /content/Construction-Site-Safety-28/test/images/Inside-merge_mov-58_jpg.rf.50147e19cb655e74c2df0047113e82b2.jpg: 640x640 (no detections), 8.3ms\n",
            "image 26/82 /content/Construction-Site-Safety-28/test/images/Movie-on-10-31-22-at-10_08-AM_mov-20_jpg.rf.aea4278b41550cdb75df5891a26052e7.jpg: 640x640 1 Mask, 8.3ms\n",
            "image 27/82 /content/Construction-Site-Safety-28/test/images/Movie-on-10-31-22-at-10_08-AM_mov-24_jpg.rf.c50014f3510a484e5bd565460fd0fd5c.jpg: 640x640 1 Mask, 1 Person, 8.4ms\n",
            "image 28/82 /content/Construction-Site-Safety-28/test/images/NX_img_177_jpg.rf.c03709e5fadfe2109411f05a9e9bc25f.jpg: 640x640 1 Hardhat, 5 Persons, 8.4ms\n",
            "image 29/82 /content/Construction-Site-Safety-28/test/images/RPReplay_Final1667001201_MP4-100_jpg.rf.9a1b50c4301c53b3ae534c6353337df9.jpg: 640x640 (no detections), 8.4ms\n",
            "image 30/82 /content/Construction-Site-Safety-28/test/images/autox3_mp4-187_jpg.rf.8340e2bd65afade3fb0d3194eadc5796.jpg: 640x640 8 Safety Cones, 1 machinery, 8.2ms\n",
            "image 31/82 /content/Construction-Site-Safety-28/test/images/autox3_mp4-277_jpg.rf.a5ed8fd043fe7e1d8682768880b6d4db.jpg: 640x640 2 Persons, 12 Safety Cones, 1 machinery, 8.4ms\n",
            "image 32/82 /content/Construction-Site-Safety-28/test/images/autox3_mp4-65_jpg.rf.d933ce48947fa9bdb55dc702a0879ac9.jpg: 640x640 3 Safety Cones, 1 machinery, 8.7ms\n",
            "image 33/82 /content/Construction-Site-Safety-28/test/images/autox_mp4-44_jpg.rf.5048603ee6ccedf9ae6e3f787b7f82ff.jpg: 640x640 1 NO-Safety Vest, 1 Person, 15 Safety Cones, 8.4ms\n",
            "image 34/82 /content/Construction-Site-Safety-28/test/images/bookstore_44_08_flickr_jpg.rf.244b6f308c529933af798c4063e58601.jpg: 640x640 2 NO-Masks, 1 NO-Safety Vest, 1 Person, 2 machinerys, 8.4ms\n",
            "image 35/82 /content/Construction-Site-Safety-28/test/images/class1_150_jpg.rf.5995dce34d38deb9eb0b6e36cae78f17.jpg: 640x640 1 Hardhat, 2 Persons, 8.7ms\n",
            "image 36/82 /content/Construction-Site-Safety-28/test/images/class2_131_jpg.rf.ad8314a9273471f1280ce8789ea75376.jpg: 640x640 1 Person, 8.4ms\n",
            "image 37/82 /content/Construction-Site-Safety-28/test/images/class2_145_jpg.rf.b8ed5a5357ee41f8fb1aa9b01a400d51.jpg: 640x640 2 Persons, 8.4ms\n",
            "image 38/82 /content/Construction-Site-Safety-28/test/images/construction-1159-_jpg.rf.9f3172102a34edb157b556a73931c831.jpg: 640x640 1 machinery, 8.6ms\n",
            "image 39/82 /content/Construction-Site-Safety-28/test/images/construction-192-_jpg.rf.56dd5c4c1396c6ad01be4fbec3bca46f.jpg: 640x640 3 machinerys, 8.2ms\n",
            "image 40/82 /content/Construction-Site-Safety-28/test/images/construction-2-_mp4-13_jpg.rf.cef0975976346515d438e0c2ce6c59db.jpg: 640x640 5 machinerys, 8.3ms\n",
            "image 41/82 /content/Construction-Site-Safety-28/test/images/construction-2-_mp4-162_jpg.rf.efad5f15524c736fe03b9c9936adc481.jpg: 640x640 2 machinerys, 8.4ms\n",
            "image 42/82 /content/Construction-Site-Safety-28/test/images/construction-2-_mp4-84_jpg.rf.e8d6bb0acc5c6e82c1a2d260ddf3135e.jpg: 640x640 3 machinerys, 8.3ms\n",
            "image 43/82 /content/Construction-Site-Safety-28/test/images/construction-275-_jpg.rf.e1c57987f9dc262aad1d7c67b694fd87.jpg: 640x640 2 machinerys, 8.3ms\n",
            "image 44/82 /content/Construction-Site-Safety-28/test/images/construction-597-_jpg.rf.e18e918aae0aeecfdf8348513636d344.jpg: 640x640 2 machinerys, 8.3ms\n",
            "image 45/82 /content/Construction-Site-Safety-28/test/images/construction-639-_jpg.rf.7db2168ad99f643f7e3070733387e3bb.jpg: 640x640 1 machinery, 8.6ms\n",
            "image 46/82 /content/Construction-Site-Safety-28/test/images/construction-651-_jpg.rf.8fa283ce7693dbdf29eb98384f24cb85.jpg: 640x640 1 machinery, 8.4ms\n",
            "image 47/82 /content/Construction-Site-Safety-28/test/images/construction-675-_jpg.rf.bb4a05441be707256175e04929da3478.jpg: 640x640 3 machinerys, 8.4ms\n",
            "image 48/82 /content/Construction-Site-Safety-28/test/images/construction-800-_jpg.rf.a01fcddd0db9cc89c0cacf4af88c468d.jpg: 640x640 2 machinerys, 8.7ms\n",
            "image 49/82 /content/Construction-Site-Safety-28/test/images/construction-843-_jpg.rf.c0ca85a10f6ad3c1375b37e52a51eeed.jpg: 640x640 5 machinerys, 8.3ms\n",
            "image 50/82 /content/Construction-Site-Safety-28/test/images/image_53_jpg.rf.3446e366b5d4d905a32e1aedc8fe87de.jpg: 640x640 2 Hardhats, 1 Mask, 1 Person, 1 Safety Vest, 2 machinerys, 8.2ms\n",
            "image 51/82 /content/Construction-Site-Safety-28/test/images/image_55_jpg.rf.27ae4341a9b9647d73a8929ff7a22369.jpg: 640x640 1 Hardhat, 2 NO-Masks, 1 Person, 1 Safety Vest, 18.7ms\n",
            "image 52/82 /content/Construction-Site-Safety-28/test/images/ka_01181_png_jpg.rf.154ee4ef254eabd62e316be50470c578.jpg: 640x640 6 Safety Cones, 8.2ms\n",
            "image 53/82 /content/Construction-Site-Safety-28/test/images/librairie_51_jpg.rf.56b0500ae2ad3820b4286133b627e59c.jpg: 640x640 (no detections), 8.2ms\n",
            "image 54/82 /content/Construction-Site-Safety-28/test/images/maksssksksss17_png_jpg.rf.f685b497756b1facbf3d4c2d2d22c0d2.jpg: 640x640 1 Mask, 1 Person, 8.2ms\n",
            "image 55/82 /content/Construction-Site-Safety-28/test/images/ppe_0018_jpg.rf.be66fabcc8627f60d963454b5a227095.jpg: 640x640 2 Hardhats, 1 NO-Hardhat, 8 NO-Masks, 2 NO-Safety Vests, 2 Persons, 8.2ms\n",
            "image 56/82 /content/Construction-Site-Safety-28/test/images/ppe_1073_jpg.rf.72ea8a293a4f3e1135219e33701b1099.jpg: 640x640 7 Hardhats, 3 NO-Masks, 14 Persons, 1 Safety Cone, 10 Safety Vests, 1 machinery, 8.1ms\n",
            "image 57/82 /content/Construction-Site-Safety-28/test/images/thumbnail-ba5c72edb320b49a69e86b05775c49b2-scaled-1_jpeg_jpg.rf.3bb460e284098219861b894fb0db13d5.jpg: 640x640 4 Hardhats, 1 Mask, 2 NO-Hardhats, 7 NO-Masks, 3 NO-Safety Vests, 13 Persons, 6 Safety Vests, 8.4ms\n",
            "image 58/82 /content/Construction-Site-Safety-28/test/images/youtube-108_jpg.rf.9dc7ed5f816f07d520f3dbfaad08d40f.jpg: 640x640 4 Hardhats, 2 NO-Masks, 2 Persons, 2 Safety Vests, 8.3ms\n",
            "image 59/82 /content/Construction-Site-Safety-28/test/images/youtube-114_jpg.rf.5e02b6574ace1f4b3689befbc5051cd0.jpg: 640x640 1 NO-Mask, 1 Person, 8.1ms\n",
            "image 60/82 /content/Construction-Site-Safety-28/test/images/youtube-126_jpg.rf.786824e90daf3276130ca73ca610a8da.jpg: 640x640 1 Hardhat, 2 NO-Masks, 5 Persons, 3 machinerys, 8.1ms\n",
            "image 61/82 /content/Construction-Site-Safety-28/test/images/youtube-152_jpg.rf.9147878e3ddda845e58f7d9c041f1338.jpg: 640x640 7 machinerys, 2 vehicles, 8.3ms\n",
            "image 62/82 /content/Construction-Site-Safety-28/test/images/youtube-186_jpg.rf.1f1d93447d4be3233c22c4ce9f6e0601.jpg: 640x640 2 Persons, 1 Safety Vest, 2 machinerys, 8.2ms\n",
            "image 63/82 /content/Construction-Site-Safety-28/test/images/youtube-192_jpg.rf.93bea040de8cd55f34ffb12f6ffe30b1.jpg: 640x640 1 NO-Mask, 1 Person, 1 Safety Vest, 8.1ms\n",
            "image 64/82 /content/Construction-Site-Safety-28/test/images/youtube-198_jpg.rf.e89faeb9765c6bd6cece5434d140f4af.jpg: 640x640 1 machinery, 8.1ms\n",
            "image 65/82 /content/Construction-Site-Safety-28/test/images/youtube-213_jpg.rf.da70b1d8cefd3cc9d56e43bb88dfb67d.jpg: 640x640 1 machinery, 8.3ms\n",
            "image 66/82 /content/Construction-Site-Safety-28/test/images/youtube-237_jpg.rf.d07a927721fe259757237c3706ea22e5.jpg: 640x640 3 Persons, 4 Safety Vests, 9 machinerys, 2 vehicles, 8.6ms\n",
            "image 67/82 /content/Construction-Site-Safety-28/test/images/youtube-253_jpg.rf.5ad0a2d701e20141940508b809584856.jpg: 640x640 (no detections), 8.5ms\n",
            "image 68/82 /content/Construction-Site-Safety-28/test/images/youtube-263_jpg.rf.374e343e12ead395440dbd81417e1be9.jpg: 640x640 2 Persons, 4 vehicles, 8.3ms\n",
            "image 69/82 /content/Construction-Site-Safety-28/test/images/youtube-263_jpg.rf.bb17b89dd2ec9a090ce53b728f48865e.jpg: 640x640 1 Hardhat, 1 Person, 1 Safety Vest, 8.3ms\n",
            "image 70/82 /content/Construction-Site-Safety-28/test/images/youtube-34_jpg.rf.03eacc444bae3c5caa3fef5c736c3e40.jpg: 640x640 3 Persons, 3 machinerys, 1 vehicle, 8.3ms\n",
            "image 71/82 /content/Construction-Site-Safety-28/test/images/youtube-388_jpg.rf.18caa1da4f818a65f73e48463cb2270e.jpg: 640x640 2 machinerys, 8.2ms\n",
            "image 72/82 /content/Construction-Site-Safety-28/test/images/youtube-462_jpg.rf.df73aa5089a04b8fbf3adf9d614a6740.jpg: 640x640 1 Hardhat, 1 Person, 1 Safety Cone, 3 Safety Vests, 1 machinery, 1 vehicle, 8.4ms\n",
            "image 73/82 /content/Construction-Site-Safety-28/test/images/youtube-471_jpg.rf.4296b7bd9a5a07753077beddbcd651bf.jpg: 640x640 (no detections), 9.0ms\n",
            "image 74/82 /content/Construction-Site-Safety-28/test/images/youtube-472_jpg.rf.e9425ff40c0df2beeef70abbc2324956.jpg: 640x640 (no detections), 8.6ms\n",
            "image 75/82 /content/Construction-Site-Safety-28/test/images/youtube-496_jpg.rf.def4e9964e9a354d0a02f4ac14334a73.jpg: 640x640 (no detections), 8.2ms\n",
            "image 76/82 /content/Construction-Site-Safety-28/test/images/youtube-510_jpg.rf.62f82e36d134d53587edb48f291986f4.jpg: 640x640 (no detections), 8.5ms\n",
            "image 77/82 /content/Construction-Site-Safety-28/test/images/youtube-53_jpg.rf.e96f8f81389f4e63a79663095680a617.jpg: 640x640 1 Hardhat, 2 Persons, 1 Safety Vest, 2 machinerys, 1 vehicle, 8.2ms\n",
            "image 78/82 /content/Construction-Site-Safety-28/test/images/youtube-596_jpg.rf.11a8a4ac01d8aadb80eeb0406dfa579a.jpg: 640x640 1 Person, 8.3ms\n",
            "image 79/82 /content/Construction-Site-Safety-28/test/images/youtube-631_jpg.rf.7c6ecf859c1b0a659f8ea057ad27aebd.jpg: 640x640 1 Person, 8.5ms\n",
            "image 80/82 /content/Construction-Site-Safety-28/test/images/youtube-671_jpg.rf.7b08643d6754cabe6caf2b49a963de47.jpg: 640x640 (no detections), 8.1ms\n",
            "image 81/82 /content/Construction-Site-Safety-28/test/images/youtube-738_jpg.rf.6f300b76e12b325f7c373c95ef319005.jpg: 640x640 1 Hardhat, 1 Person, 8.2ms\n",
            "image 82/82 /content/Construction-Site-Safety-28/test/images/youtube-840_jpg.rf.974a83a7c5aee7c16e83435b043c6d96.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 Safety Vest, 1 machinery, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train24\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the current and new folder paths for later usage (to check plots for each model)\n",
        "old_folder_path = '/content/runs/detect/train'\n",
        "new_folder_path = '/content/runs/detect/train_yolov8n_finetune'"
      ],
      "metadata": {
        "id": "xbmRGR6tBRJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning"
      ],
      "metadata": {
        "id": "t0mgLKr4BZKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLOv8n BACKBONE freeze"
      ],
      "metadata": {
        "id": "zpPPOmqZtJZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_layer(trainer):\n",
        "    model = trainer.model\n",
        "    num_freeze = 10\n",
        "    print(f\"Freezing {num_freeze} layers\")\n",
        "    freeze = [f'model.{x}.' for x in range(num_freeze)]  # layers to freeze\n",
        "    for k, v in model.named_parameters():\n",
        "        v.requires_grad = True  # train all layers\n",
        "        if any(x in k for x in freeze):\n",
        "            print(f'freezing {k}')\n",
        "            v.requires_grad = False\n",
        "    print(f\"{num_freeze} layers are freezed.\")"
      ],
      "metadata": {
        "id": "RfZG-J3okTzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolov8n_transfer = YOLO('yolov8n.yaml').load('yolov8n.pt')\n",
        "for layer in yolov8n_transfer.modules():\n",
        "    print(layer)\n",
        "\n",
        "for name, parameter in yolov8n_transfer.named_parameters():\n",
        "  layer_number = int(name.split('.')[2])\n",
        "  if layer_number <= 9:\n",
        "    parameter.requires_grad = False\n",
        "  print(name, layer_number, parameter.requires_grad)"
      ],
      "metadata": {
        "id": "MMLuSNAttN22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce7bb0d-fbdb-48bf-ffcf-5c4219080842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 355/355 items from pretrained weights\n",
            "YOLO(\n",
            "  (model): DetectionModel(\n",
            "    (model): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): Conv(\n",
            "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (4): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-1): 2 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): Conv(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (6): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-1): 2 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (7): Conv(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (8): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (9): SPPF(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (11): Concat()\n",
            "      (12): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (14): Concat()\n",
            "      (15): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (16): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (17): Concat()\n",
            "      (18): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (19): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (20): Concat()\n",
            "      (21): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (22): Detect(\n",
            "        (cv2): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (cv3): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (dfl): DFL(\n",
            "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "DetectionModel(\n",
            "  (model): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Conv(\n",
            "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (4): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0-1): 2 x Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): Conv(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (6): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0-1): 2 x Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): Conv(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (8): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): SPPF(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (11): Concat()\n",
            "    (12): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (14): Concat()\n",
            "    (15): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (16): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (17): Concat()\n",
            "    (18): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (19): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (20): Concat()\n",
            "    (21): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (22): Detect(\n",
            "      (cv2): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (cv3): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (dfl): DFL(\n",
            "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Sequential(\n",
            "  (0): Conv(\n",
            "    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (1): Conv(\n",
            "    (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (2): C2f(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): ModuleList(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (3): Conv(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (4): C2f(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): ModuleList(\n",
            "      (0-1): 2 x Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (5): Conv(\n",
            "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (6): C2f(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): ModuleList(\n",
            "      (0-1): 2 x Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (7): Conv(\n",
            "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (8): C2f(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): ModuleList(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (9): SPPF(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (11): Concat()\n",
            "  (12): C2f(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): ModuleList(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (13): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (14): Concat()\n",
            "  (15): C2f(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): ModuleList(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (16): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (17): Concat()\n",
            "  (18): C2f(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): ModuleList(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (19): Conv(\n",
            "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (20): Concat()\n",
            "  (21): C2f(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (m): ModuleList(\n",
            "      (0): Bottleneck(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (22): Detect(\n",
            "    (cv2): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (cv3): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (dfl): DFL(\n",
            "      (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "SiLU(inplace=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "C2f(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (m): ModuleList(\n",
            "    (0): Bottleneck(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "ModuleList(\n",
            "  (0): Bottleneck(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Bottleneck(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "C2f(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (m): ModuleList(\n",
            "    (0-1): 2 x Bottleneck(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "ModuleList(\n",
            "  (0-1): 2 x Bottleneck(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Bottleneck(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Bottleneck(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "C2f(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (m): ModuleList(\n",
            "    (0-1): 2 x Bottleneck(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "ModuleList(\n",
            "  (0-1): 2 x Bottleneck(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Bottleneck(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Bottleneck(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "C2f(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (m): ModuleList(\n",
            "    (0): Bottleneck(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "ModuleList(\n",
            "  (0): Bottleneck(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Bottleneck(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "SPPF(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "Upsample(scale_factor=2.0, mode='nearest')\n",
            "Concat()\n",
            "C2f(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (m): ModuleList(\n",
            "    (0): Bottleneck(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "ModuleList(\n",
            "  (0): Bottleneck(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Bottleneck(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Upsample(scale_factor=2.0, mode='nearest')\n",
            "Concat()\n",
            "C2f(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (m): ModuleList(\n",
            "    (0): Bottleneck(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "ModuleList(\n",
            "  (0): Bottleneck(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Bottleneck(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Concat()\n",
            "C2f(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (m): ModuleList(\n",
            "    (0): Bottleneck(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "ModuleList(\n",
            "  (0): Bottleneck(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Bottleneck(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Concat()\n",
            "C2f(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (m): ModuleList(\n",
            "    (0): Bottleneck(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "ModuleList(\n",
            "  (0): Bottleneck(\n",
            "    (cv1): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (cv2): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Bottleneck(\n",
            "  (cv1): Conv(\n",
            "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (cv2): Conv(\n",
            "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Detect(\n",
            "  (cv2): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (cv3): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (dfl): DFL(\n",
            "    (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "ModuleList(\n",
            "  (0): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "Sequential(\n",
            "  (0): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (1): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "Sequential(\n",
            "  (0): Conv(\n",
            "    (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (1): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "Sequential(\n",
            "  (0): Conv(\n",
            "    (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (1): Conv(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "ModuleList(\n",
            "  (0): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "Sequential(\n",
            "  (0): Conv(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (1): Conv(\n",
            "    (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "Sequential(\n",
            "  (0): Conv(\n",
            "    (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (1): Conv(\n",
            "    (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "Sequential(\n",
            "  (0): Conv(\n",
            "    (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (1): Conv(\n",
            "    (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "    (act): SiLU(inplace=True)\n",
            "  )\n",
            "  (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Conv(\n",
            "  (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv(\n",
            "  (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "  (act): SiLU(inplace=True)\n",
            ")\n",
            "Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "DFL(\n",
            "  (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            ")\n",
            "Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "model.model.0.conv.weight 0 False\n",
            "model.model.0.bn.weight 0 False\n",
            "model.model.0.bn.bias 0 False\n",
            "model.model.1.conv.weight 1 False\n",
            "model.model.1.bn.weight 1 False\n",
            "model.model.1.bn.bias 1 False\n",
            "model.model.2.cv1.conv.weight 2 False\n",
            "model.model.2.cv1.bn.weight 2 False\n",
            "model.model.2.cv1.bn.bias 2 False\n",
            "model.model.2.cv2.conv.weight 2 False\n",
            "model.model.2.cv2.bn.weight 2 False\n",
            "model.model.2.cv2.bn.bias 2 False\n",
            "model.model.2.m.0.cv1.conv.weight 2 False\n",
            "model.model.2.m.0.cv1.bn.weight 2 False\n",
            "model.model.2.m.0.cv1.bn.bias 2 False\n",
            "model.model.2.m.0.cv2.conv.weight 2 False\n",
            "model.model.2.m.0.cv2.bn.weight 2 False\n",
            "model.model.2.m.0.cv2.bn.bias 2 False\n",
            "model.model.3.conv.weight 3 False\n",
            "model.model.3.bn.weight 3 False\n",
            "model.model.3.bn.bias 3 False\n",
            "model.model.4.cv1.conv.weight 4 False\n",
            "model.model.4.cv1.bn.weight 4 False\n",
            "model.model.4.cv1.bn.bias 4 False\n",
            "model.model.4.cv2.conv.weight 4 False\n",
            "model.model.4.cv2.bn.weight 4 False\n",
            "model.model.4.cv2.bn.bias 4 False\n",
            "model.model.4.m.0.cv1.conv.weight 4 False\n",
            "model.model.4.m.0.cv1.bn.weight 4 False\n",
            "model.model.4.m.0.cv1.bn.bias 4 False\n",
            "model.model.4.m.0.cv2.conv.weight 4 False\n",
            "model.model.4.m.0.cv2.bn.weight 4 False\n",
            "model.model.4.m.0.cv2.bn.bias 4 False\n",
            "model.model.4.m.1.cv1.conv.weight 4 False\n",
            "model.model.4.m.1.cv1.bn.weight 4 False\n",
            "model.model.4.m.1.cv1.bn.bias 4 False\n",
            "model.model.4.m.1.cv2.conv.weight 4 False\n",
            "model.model.4.m.1.cv2.bn.weight 4 False\n",
            "model.model.4.m.1.cv2.bn.bias 4 False\n",
            "model.model.5.conv.weight 5 False\n",
            "model.model.5.bn.weight 5 False\n",
            "model.model.5.bn.bias 5 False\n",
            "model.model.6.cv1.conv.weight 6 False\n",
            "model.model.6.cv1.bn.weight 6 False\n",
            "model.model.6.cv1.bn.bias 6 False\n",
            "model.model.6.cv2.conv.weight 6 False\n",
            "model.model.6.cv2.bn.weight 6 False\n",
            "model.model.6.cv2.bn.bias 6 False\n",
            "model.model.6.m.0.cv1.conv.weight 6 False\n",
            "model.model.6.m.0.cv1.bn.weight 6 False\n",
            "model.model.6.m.0.cv1.bn.bias 6 False\n",
            "model.model.6.m.0.cv2.conv.weight 6 False\n",
            "model.model.6.m.0.cv2.bn.weight 6 False\n",
            "model.model.6.m.0.cv2.bn.bias 6 False\n",
            "model.model.6.m.1.cv1.conv.weight 6 False\n",
            "model.model.6.m.1.cv1.bn.weight 6 False\n",
            "model.model.6.m.1.cv1.bn.bias 6 False\n",
            "model.model.6.m.1.cv2.conv.weight 6 False\n",
            "model.model.6.m.1.cv2.bn.weight 6 False\n",
            "model.model.6.m.1.cv2.bn.bias 6 False\n",
            "model.model.7.conv.weight 7 False\n",
            "model.model.7.bn.weight 7 False\n",
            "model.model.7.bn.bias 7 False\n",
            "model.model.8.cv1.conv.weight 8 False\n",
            "model.model.8.cv1.bn.weight 8 False\n",
            "model.model.8.cv1.bn.bias 8 False\n",
            "model.model.8.cv2.conv.weight 8 False\n",
            "model.model.8.cv2.bn.weight 8 False\n",
            "model.model.8.cv2.bn.bias 8 False\n",
            "model.model.8.m.0.cv1.conv.weight 8 False\n",
            "model.model.8.m.0.cv1.bn.weight 8 False\n",
            "model.model.8.m.0.cv1.bn.bias 8 False\n",
            "model.model.8.m.0.cv2.conv.weight 8 False\n",
            "model.model.8.m.0.cv2.bn.weight 8 False\n",
            "model.model.8.m.0.cv2.bn.bias 8 False\n",
            "model.model.9.cv1.conv.weight 9 False\n",
            "model.model.9.cv1.bn.weight 9 False\n",
            "model.model.9.cv1.bn.bias 9 False\n",
            "model.model.9.cv2.conv.weight 9 False\n",
            "model.model.9.cv2.bn.weight 9 False\n",
            "model.model.9.cv2.bn.bias 9 False\n",
            "model.model.12.cv1.conv.weight 12 True\n",
            "model.model.12.cv1.bn.weight 12 True\n",
            "model.model.12.cv1.bn.bias 12 True\n",
            "model.model.12.cv2.conv.weight 12 True\n",
            "model.model.12.cv2.bn.weight 12 True\n",
            "model.model.12.cv2.bn.bias 12 True\n",
            "model.model.12.m.0.cv1.conv.weight 12 True\n",
            "model.model.12.m.0.cv1.bn.weight 12 True\n",
            "model.model.12.m.0.cv1.bn.bias 12 True\n",
            "model.model.12.m.0.cv2.conv.weight 12 True\n",
            "model.model.12.m.0.cv2.bn.weight 12 True\n",
            "model.model.12.m.0.cv2.bn.bias 12 True\n",
            "model.model.15.cv1.conv.weight 15 True\n",
            "model.model.15.cv1.bn.weight 15 True\n",
            "model.model.15.cv1.bn.bias 15 True\n",
            "model.model.15.cv2.conv.weight 15 True\n",
            "model.model.15.cv2.bn.weight 15 True\n",
            "model.model.15.cv2.bn.bias 15 True\n",
            "model.model.15.m.0.cv1.conv.weight 15 True\n",
            "model.model.15.m.0.cv1.bn.weight 15 True\n",
            "model.model.15.m.0.cv1.bn.bias 15 True\n",
            "model.model.15.m.0.cv2.conv.weight 15 True\n",
            "model.model.15.m.0.cv2.bn.weight 15 True\n",
            "model.model.15.m.0.cv2.bn.bias 15 True\n",
            "model.model.16.conv.weight 16 True\n",
            "model.model.16.bn.weight 16 True\n",
            "model.model.16.bn.bias 16 True\n",
            "model.model.18.cv1.conv.weight 18 True\n",
            "model.model.18.cv1.bn.weight 18 True\n",
            "model.model.18.cv1.bn.bias 18 True\n",
            "model.model.18.cv2.conv.weight 18 True\n",
            "model.model.18.cv2.bn.weight 18 True\n",
            "model.model.18.cv2.bn.bias 18 True\n",
            "model.model.18.m.0.cv1.conv.weight 18 True\n",
            "model.model.18.m.0.cv1.bn.weight 18 True\n",
            "model.model.18.m.0.cv1.bn.bias 18 True\n",
            "model.model.18.m.0.cv2.conv.weight 18 True\n",
            "model.model.18.m.0.cv2.bn.weight 18 True\n",
            "model.model.18.m.0.cv2.bn.bias 18 True\n",
            "model.model.19.conv.weight 19 True\n",
            "model.model.19.bn.weight 19 True\n",
            "model.model.19.bn.bias 19 True\n",
            "model.model.21.cv1.conv.weight 21 True\n",
            "model.model.21.cv1.bn.weight 21 True\n",
            "model.model.21.cv1.bn.bias 21 True\n",
            "model.model.21.cv2.conv.weight 21 True\n",
            "model.model.21.cv2.bn.weight 21 True\n",
            "model.model.21.cv2.bn.bias 21 True\n",
            "model.model.21.m.0.cv1.conv.weight 21 True\n",
            "model.model.21.m.0.cv1.bn.weight 21 True\n",
            "model.model.21.m.0.cv1.bn.bias 21 True\n",
            "model.model.21.m.0.cv2.conv.weight 21 True\n",
            "model.model.21.m.0.cv2.bn.weight 21 True\n",
            "model.model.21.m.0.cv2.bn.bias 21 True\n",
            "model.model.22.cv2.0.0.conv.weight 22 True\n",
            "model.model.22.cv2.0.0.bn.weight 22 True\n",
            "model.model.22.cv2.0.0.bn.bias 22 True\n",
            "model.model.22.cv2.0.1.conv.weight 22 True\n",
            "model.model.22.cv2.0.1.bn.weight 22 True\n",
            "model.model.22.cv2.0.1.bn.bias 22 True\n",
            "model.model.22.cv2.0.2.weight 22 True\n",
            "model.model.22.cv2.0.2.bias 22 True\n",
            "model.model.22.cv2.1.0.conv.weight 22 True\n",
            "model.model.22.cv2.1.0.bn.weight 22 True\n",
            "model.model.22.cv2.1.0.bn.bias 22 True\n",
            "model.model.22.cv2.1.1.conv.weight 22 True\n",
            "model.model.22.cv2.1.1.bn.weight 22 True\n",
            "model.model.22.cv2.1.1.bn.bias 22 True\n",
            "model.model.22.cv2.1.2.weight 22 True\n",
            "model.model.22.cv2.1.2.bias 22 True\n",
            "model.model.22.cv2.2.0.conv.weight 22 True\n",
            "model.model.22.cv2.2.0.bn.weight 22 True\n",
            "model.model.22.cv2.2.0.bn.bias 22 True\n",
            "model.model.22.cv2.2.1.conv.weight 22 True\n",
            "model.model.22.cv2.2.1.bn.weight 22 True\n",
            "model.model.22.cv2.2.1.bn.bias 22 True\n",
            "model.model.22.cv2.2.2.weight 22 True\n",
            "model.model.22.cv2.2.2.bias 22 True\n",
            "model.model.22.cv3.0.0.conv.weight 22 True\n",
            "model.model.22.cv3.0.0.bn.weight 22 True\n",
            "model.model.22.cv3.0.0.bn.bias 22 True\n",
            "model.model.22.cv3.0.1.conv.weight 22 True\n",
            "model.model.22.cv3.0.1.bn.weight 22 True\n",
            "model.model.22.cv3.0.1.bn.bias 22 True\n",
            "model.model.22.cv3.0.2.weight 22 True\n",
            "model.model.22.cv3.0.2.bias 22 True\n",
            "model.model.22.cv3.1.0.conv.weight 22 True\n",
            "model.model.22.cv3.1.0.bn.weight 22 True\n",
            "model.model.22.cv3.1.0.bn.bias 22 True\n",
            "model.model.22.cv3.1.1.conv.weight 22 True\n",
            "model.model.22.cv3.1.1.bn.weight 22 True\n",
            "model.model.22.cv3.1.1.bn.bias 22 True\n",
            "model.model.22.cv3.1.2.weight 22 True\n",
            "model.model.22.cv3.1.2.bias 22 True\n",
            "model.model.22.cv3.2.0.conv.weight 22 True\n",
            "model.model.22.cv3.2.0.bn.weight 22 True\n",
            "model.model.22.cv3.2.0.bn.bias 22 True\n",
            "model.model.22.cv3.2.1.conv.weight 22 True\n",
            "model.model.22.cv3.2.1.bn.weight 22 True\n",
            "model.model.22.cv3.2.1.bn.bias 22 True\n",
            "model.model.22.cv3.2.2.weight 22 True\n",
            "model.model.22.cv3.2.2.bias 22 True\n",
            "model.model.22.dfl.conv.weight 22 False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yolov8n_transfer.add_callback(\"on_train_start\", freeze_layer)"
      ],
      "metadata": {
        "id": "Dc-vssFJkV-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = 0\n",
        "trainable_layers = 0\n",
        "\n",
        "for name, parameter in yolov8n_transfer.named_parameters():\n",
        "  # print(parameter.requires_grad)\n",
        "  if parameter.requires_grad:\n",
        "        # Counting the number of trainable parameters\n",
        "        trainable_params += parameter.numel()\n",
        "        # Each layer with at least one trainable parameter is considered a trainable layer\n",
        "        trainable_layers += 1\n"
      ],
      "metadata": {
        "id": "HwQ_gGPokXG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih5fof7Cue8u",
        "outputId": "54825744-c777-427f-fbd9-cba7be3d9538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1884528"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_model = yolov8n_transfer.train(data= data_yaml, epochs= 40, imgsz=640, patience = 3, plots=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klb5n4CIk_G7",
        "outputId": "146d83f1-f989-436d-b400-c1801d4d52eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.25 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/Construction-Site-Safety-28/data.yaml, epochs=40, time=None, patience=3, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
            "YOLOv8n summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Construction-Site-Safety-28/train/labels.cache... 2605 images, 6 backgrounds, 0 corrupt: 100%|██████████| 2605/2605 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/Construction-Site-Safety-28/train/images/004720_jpg.rf.afc486560a4004c7cfd67910af31a29c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/Construction-Site-Safety-28/train/images/construction-813-_jpg.rf.b085952261fd98f2e76b8065de149b5f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Construction-Site-Safety-28/valid/labels.cache... 114 images, 10 backgrounds, 0 corrupt: 100%|██████████| 114/114 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train5/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Freezing 10 layers\n",
            "freezing model.0.conv.weight\n",
            "freezing model.0.bn.weight\n",
            "freezing model.0.bn.bias\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "freezing model.2.cv1.conv.weight\n",
            "freezing model.2.cv1.bn.weight\n",
            "freezing model.2.cv1.bn.bias\n",
            "freezing model.2.cv2.conv.weight\n",
            "freezing model.2.cv2.bn.weight\n",
            "freezing model.2.cv2.bn.bias\n",
            "freezing model.2.m.0.cv1.conv.weight\n",
            "freezing model.2.m.0.cv1.bn.weight\n",
            "freezing model.2.m.0.cv1.bn.bias\n",
            "freezing model.2.m.0.cv2.conv.weight\n",
            "freezing model.2.m.0.cv2.bn.weight\n",
            "freezing model.2.m.0.cv2.bn.bias\n",
            "freezing model.3.conv.weight\n",
            "freezing model.3.bn.weight\n",
            "freezing model.3.bn.bias\n",
            "freezing model.4.cv1.conv.weight\n",
            "freezing model.4.cv1.bn.weight\n",
            "freezing model.4.cv1.bn.bias\n",
            "freezing model.4.cv2.conv.weight\n",
            "freezing model.4.cv2.bn.weight\n",
            "freezing model.4.cv2.bn.bias\n",
            "freezing model.4.m.0.cv1.conv.weight\n",
            "freezing model.4.m.0.cv1.bn.weight\n",
            "freezing model.4.m.0.cv1.bn.bias\n",
            "freezing model.4.m.0.cv2.conv.weight\n",
            "freezing model.4.m.0.cv2.bn.weight\n",
            "freezing model.4.m.0.cv2.bn.bias\n",
            "freezing model.4.m.1.cv1.conv.weight\n",
            "freezing model.4.m.1.cv1.bn.weight\n",
            "freezing model.4.m.1.cv1.bn.bias\n",
            "freezing model.4.m.1.cv2.conv.weight\n",
            "freezing model.4.m.1.cv2.bn.weight\n",
            "freezing model.4.m.1.cv2.bn.bias\n",
            "freezing model.5.conv.weight\n",
            "freezing model.5.bn.weight\n",
            "freezing model.5.bn.bias\n",
            "freezing model.6.cv1.conv.weight\n",
            "freezing model.6.cv1.bn.weight\n",
            "freezing model.6.cv1.bn.bias\n",
            "freezing model.6.cv2.conv.weight\n",
            "freezing model.6.cv2.bn.weight\n",
            "freezing model.6.cv2.bn.bias\n",
            "freezing model.6.m.0.cv1.conv.weight\n",
            "freezing model.6.m.0.cv1.bn.weight\n",
            "freezing model.6.m.0.cv1.bn.bias\n",
            "freezing model.6.m.0.cv2.conv.weight\n",
            "freezing model.6.m.0.cv2.bn.weight\n",
            "freezing model.6.m.0.cv2.bn.bias\n",
            "freezing model.6.m.1.cv1.conv.weight\n",
            "freezing model.6.m.1.cv1.bn.weight\n",
            "freezing model.6.m.1.cv1.bn.bias\n",
            "freezing model.6.m.1.cv2.conv.weight\n",
            "freezing model.6.m.1.cv2.bn.weight\n",
            "freezing model.6.m.1.cv2.bn.bias\n",
            "freezing model.7.conv.weight\n",
            "freezing model.7.bn.weight\n",
            "freezing model.7.bn.bias\n",
            "freezing model.8.cv1.conv.weight\n",
            "freezing model.8.cv1.bn.weight\n",
            "freezing model.8.cv1.bn.bias\n",
            "freezing model.8.cv2.conv.weight\n",
            "freezing model.8.cv2.bn.weight\n",
            "freezing model.8.cv2.bn.bias\n",
            "freezing model.8.m.0.cv1.conv.weight\n",
            "freezing model.8.m.0.cv1.bn.weight\n",
            "freezing model.8.m.0.cv1.bn.bias\n",
            "freezing model.8.m.0.cv2.conv.weight\n",
            "freezing model.8.m.0.cv2.bn.weight\n",
            "freezing model.8.m.0.cv2.bn.bias\n",
            "freezing model.9.cv1.conv.weight\n",
            "freezing model.9.cv1.bn.weight\n",
            "freezing model.9.cv1.bn.bias\n",
            "freezing model.9.cv2.conv.weight\n",
            "freezing model.9.cv2.bn.weight\n",
            "freezing model.9.cv2.bn.bias\n",
            "10 layers are freezed.\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/40      2.59G      1.451      2.937      1.532        263        640: 100%|██████████| 163/163 [00:20<00:00,  8.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.461      0.344      0.334      0.157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/40      2.09G      1.359      2.078      1.491        228        640: 100%|██████████| 163/163 [00:13<00:00, 11.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.537      0.402      0.424       0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/40      2.17G      1.306       1.84      1.449        256        640: 100%|██████████| 163/163 [00:13<00:00, 12.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.562      0.442       0.47      0.214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/40      1.99G      1.286      1.751      1.428        258        640: 100%|██████████| 163/163 [00:13<00:00, 12.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.604      0.498      0.515      0.233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/40      2.14G      1.251      1.682      1.396        386        640: 100%|██████████| 163/163 [00:13<00:00, 12.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.666      0.479      0.532       0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/40      2.24G      1.239      1.615      1.383        310        640: 100%|██████████| 163/163 [00:13<00:00, 12.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697       0.65      0.513      0.554       0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/40      2.12G      1.218      1.577      1.371        342        640: 100%|██████████| 163/163 [00:13<00:00, 12.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.662      0.513      0.555      0.247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/40       2.3G        1.2      1.531      1.352        294        640: 100%|██████████| 163/163 [00:12<00:00, 12.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.711      0.511      0.561      0.284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/40      2.52G      1.211      1.501      1.352        370        640: 100%|██████████| 163/163 [00:13<00:00, 12.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.708       0.52      0.572      0.273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/40      2.49G      1.175       1.46      1.338        320        640: 100%|██████████| 163/163 [00:12<00:00, 12.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.708      0.519      0.581      0.269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/40      2.37G      1.171       1.43      1.329        236        640: 100%|██████████| 163/163 [00:12<00:00, 12.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.717      0.528      0.592      0.288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/40       2.6G      1.152      1.406      1.316        265        640: 100%|██████████| 163/163 [00:13<00:00, 12.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.778       0.53      0.629      0.294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/40      2.98G      1.152      1.384      1.314        213        640: 100%|██████████| 163/163 [00:13<00:00, 12.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.705      0.559      0.605       0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/40      2.38G       1.15      1.365      1.309        190        640: 100%|██████████| 163/163 [00:13<00:00, 12.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.738      0.553      0.613      0.301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/40       2.4G      1.131       1.35      1.307        432        640: 100%|██████████| 163/163 [00:13<00:00, 12.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.724      0.571      0.625      0.293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/40      2.57G      1.141      1.331        1.3        323        640: 100%|██████████| 163/163 [00:13<00:00, 12.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697        0.7      0.556      0.622      0.328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/40      1.81G      1.114      1.313      1.289        295        640: 100%|██████████| 163/163 [00:12<00:00, 12.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.759       0.55      0.638      0.331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/40       2.8G      1.125      1.298      1.289        424        640: 100%|██████████| 163/163 [00:12<00:00, 12.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.795      0.564      0.645      0.337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/40      2.33G      1.116      1.292      1.289        344        640: 100%|██████████| 163/163 [00:12<00:00, 12.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.757      0.551      0.626      0.308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/40       2.5G      1.106      1.272      1.281        295        640: 100%|██████████| 163/163 [00:13<00:00, 12.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.785      0.555      0.646      0.313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/40      2.08G      1.103      1.255      1.273        352        640: 100%|██████████| 163/163 [00:13<00:00, 12.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.778      0.551      0.634      0.323\n",
            "Stopping training early as no improvement observed in last 3 epochs. Best results observed at epoch 18, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "21 epochs completed in 0.113 hours.\n",
            "Optimizer stripped from runs/detect/train5/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train5/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train5/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.25 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        114        697      0.793      0.563      0.645      0.338\n",
            "               Hardhat        114         79      0.934      0.658      0.747      0.446\n",
            "                  Mask        114         21      0.739      0.762       0.77      0.489\n",
            "            NO-Hardhat        114         69      0.746      0.406      0.537      0.209\n",
            "               NO-Mask        114         74      0.761      0.405      0.473      0.195\n",
            "        NO-Safety Vest        114        106      0.888      0.472      0.591      0.283\n",
            "                Person        114        166      0.835      0.608      0.712      0.368\n",
            "           Safety Cone        114         44      0.795       0.75      0.775      0.369\n",
            "           Safety Vest        114         41      0.883      0.555      0.713      0.397\n",
            "             machinery        114         55      0.724      0.572      0.677      0.394\n",
            "               vehicle        114         42      0.629      0.444      0.455      0.232\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train5\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_transfer_n = YOLO('/content/runs/detect/train5/weights/best.pt')"
      ],
      "metadata": {
        "id": "DbZsGsSGlCju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### get the image annotation by our model"
      ],
      "metadata": {
        "id": "CAjCfQo9r2q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = \"/content/Construction-Site-Safety-28/test/images\"\n",
        "results = model_transfer_n.predict(source=test_path, save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wafVzvTQlFhQ",
        "outputId": "985533c5-2960-469a-9f78-b7ab060146a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/82 /content/Construction-Site-Safety-28/test/images/-4405-_png_jpg.rf.82b5c10b2acd1cfaa24259ada8e599fe.jpg: 640x640 (no detections), 9.3ms\n",
            "image 2/82 /content/Construction-Site-Safety-28/test/images/000005_jpg.rf.96e9379ccae638140c4a90fc4b700a2b.jpg: 640x640 2 Hardhats, 2 NO-Masks, 1 Person, 1 vehicle, 8.5ms\n",
            "image 3/82 /content/Construction-Site-Safety-28/test/images/002551_jpg.rf.ce4b9f934161faa72c80dc6898d37b2d.jpg: 640x640 1 Hardhat, 1 NO-Mask, 3 NO-Safety Vests, 5 Persons, 8.9ms\n",
            "image 4/82 /content/Construction-Site-Safety-28/test/images/003357_jpg.rf.9867f91e88089bb68dc95947d5116d14.jpg: 640x640 1 NO-Safety Vest, 1 Person, 1 Safety Cone, 8.4ms\n",
            "image 5/82 /content/Construction-Site-Safety-28/test/images/004063_jpg.rf.1b7cdc4035bcb24ef69b8798b444053e.jpg: 640x640 4 Hardhats, 1 NO-Hardhat, 5 NO-Safety Vests, 7 Persons, 1 Safety Vest, 8.5ms\n",
            "image 6/82 /content/Construction-Site-Safety-28/test/images/004763_jpg.rf.46484e6ca73caeaa9de45822cf1085a9.jpg: 640x640 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 8.6ms\n",
            "image 7/82 /content/Construction-Site-Safety-28/test/images/006463_jpg.rf.02f19082420ecc5537b9d59abbe6050c.jpg: 640x640 9 Hardhats, 12 NO-Masks, 8 NO-Safety Vests, 11 Persons, 1 Safety Vest, 8.5ms\n",
            "image 8/82 /content/Construction-Site-Safety-28/test/images/006672_jpg.rf.87d5978c486feb53177408cf00a0d87f.jpg: 640x640 6 Hardhats, 2 NO-Masks, 6 Persons, 7 Safety Vests, 2 machinerys, 8.5ms\n",
            "image 9/82 /content/Construction-Site-Safety-28/test/images/0_jpg.rf.2ff49f74309118f169e07aa12564df87.jpg: 640x640 1 Hardhat, 4 Persons, 1 Safety Vest, 1 machinery, 8.7ms\n",
            "image 10/82 /content/Construction-Site-Safety-28/test/images/2008_008320_jpg.rf.bd34011d46f82f9410d95f00e560b8ea.jpg: 640x640 1 NO-Hardhat, 2 Persons, 1 Safety Vest, 8.6ms\n",
            "image 11/82 /content/Construction-Site-Safety-28/test/images/2008_008519_jpg.rf.1798c8eed7de04399a0e7e297b4b4c9e.jpg: 640x640 1 NO-Safety Vest, 3 Persons, 1 Safety Vest, 1 vehicle, 8.6ms\n",
            "image 12/82 /content/Construction-Site-Safety-28/test/images/2009_000059_jpg.rf.50e8398a37eb33f33fd9f662feeea083.jpg: 640x640 1 NO-Hardhat, 2 NO-Masks, 1 NO-Safety Vest, 2 Persons, 8.4ms\n",
            "image 13/82 /content/Construction-Site-Safety-28/test/images/2009_000496_jpg.rf.9a2d210fe0f5ea4b572aeb07e41ecbae.jpg: 640x640 2 Persons, 1 machinery, 8.3ms\n",
            "image 14/82 /content/Construction-Site-Safety-28/test/images/3e7e40981ddd4cdb055c7ffe4c2af5d8_jpg.rf.bac50dc18195e9aeb6f3a21782a3efcb.jpg: 640x640 (no detections), 8.3ms\n",
            "image 15/82 /content/Construction-Site-Safety-28/test/images/777_jpg.rf.92dc6945342410ced7ac93f3dfbff0c5.jpg: 640x640 1 Safety Cone, 8.3ms\n",
            "image 16/82 /content/Construction-Site-Safety-28/test/images/Bookstore_More_Merchandise_jpg.rf.7ab5add3e28ced74f9b316e794cc04d2.jpg: 640x640 1 Safety Cone, 8.4ms\n",
            "image 17/82 /content/Construction-Site-Safety-28/test/images/IMG_0871_MOV-12_jpg.rf.36858a9d51613f9a39b7855b54dfa098.jpg: 640x640 1 Mask, 1 NO-Hardhat, 2 NO-Safety Vests, 1 Person, 8.7ms\n",
            "image 18/82 /content/Construction-Site-Safety-28/test/images/IMG_0871_mp4-11_jpg.rf.432092b53ebeb84f4b9b27b40343c9aa.jpg: 640x640 3 Masks, 2 NO-Hardhats, 1 NO-Safety Vest, 1 Person, 8.6ms\n",
            "image 19/82 /content/Construction-Site-Safety-28/test/images/IMG_0871_mp4-23_jpg.rf.03f872b1ed87ad7fadc85e09475ad37a.jpg: 640x640 3 Masks, 1 NO-Hardhat, 2 NO-Safety Vests, 1 Person, 8.4ms\n",
            "image 20/82 /content/Construction-Site-Safety-28/test/images/IMG_3100_mp4-12_jpg.rf.58849ca6a931c2cfe1b17fb4206d9d82.jpg: 640x640 1 Mask, 2 NO-Hardhats, 2 NO-Safety Vests, 1 Person, 8.5ms\n",
            "image 21/82 /content/Construction-Site-Safety-28/test/images/IMG_3100_mp4-9_jpg.rf.413ccf5fe4a7ee67f71e07c2c43b6756.jpg: 640x640 1 Mask, 1 NO-Hardhat, 2 NO-Safety Vests, 1 Person, 8.4ms\n",
            "image 22/82 /content/Construction-Site-Safety-28/test/images/IMG_3103_mp4-9_jpg.rf.b31bd2d816465a27aa1eb072f90bb5aa.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.3ms\n",
            "image 23/82 /content/Construction-Site-Safety-28/test/images/IMG_5846_jpg.rf.0b9984069116e2acd928568eb7a8e214.jpg: 640x640 21 Hardhats, 33 NO-Masks, 25 Persons, 22 Safety Vests, 8.4ms\n",
            "image 24/82 /content/Construction-Site-Safety-28/test/images/Image36_jpg.rf.8704f3450f736cdd01a61dcee588f2c2.jpg: 640x640 8 Hardhats, 1 NO-Hardhat, 4 NO-Masks, 3 NO-Safety Vests, 10 Persons, 8.8ms\n",
            "image 25/82 /content/Construction-Site-Safety-28/test/images/Inside-merge_mov-58_jpg.rf.50147e19cb655e74c2df0047113e82b2.jpg: 640x640 (no detections), 9.2ms\n",
            "image 26/82 /content/Construction-Site-Safety-28/test/images/Movie-on-10-31-22-at-10_08-AM_mov-20_jpg.rf.aea4278b41550cdb75df5891a26052e7.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.4ms\n",
            "image 27/82 /content/Construction-Site-Safety-28/test/images/Movie-on-10-31-22-at-10_08-AM_mov-24_jpg.rf.c50014f3510a484e5bd565460fd0fd5c.jpg: 640x640 1 Mask, 2 NO-Hardhats, 1 NO-Safety Vest, 1 Person, 8.8ms\n",
            "image 28/82 /content/Construction-Site-Safety-28/test/images/NX_img_177_jpg.rf.c03709e5fadfe2109411f05a9e9bc25f.jpg: 640x640 1 Hardhat, 2 NO-Hardhats, 4 NO-Safety Vests, 3 Persons, 8.4ms\n",
            "image 29/82 /content/Construction-Site-Safety-28/test/images/RPReplay_Final1667001201_MP4-100_jpg.rf.9a1b50c4301c53b3ae534c6353337df9.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 2 Persons, 8.4ms\n",
            "image 30/82 /content/Construction-Site-Safety-28/test/images/autox3_mp4-187_jpg.rf.8340e2bd65afade3fb0d3194eadc5796.jpg: 640x640 5 Safety Cones, 3 vehicles, 8.3ms\n",
            "image 31/82 /content/Construction-Site-Safety-28/test/images/autox3_mp4-277_jpg.rf.a5ed8fd043fe7e1d8682768880b6d4db.jpg: 640x640 22 Safety Cones, 1 vehicle, 8.3ms\n",
            "image 32/82 /content/Construction-Site-Safety-28/test/images/autox3_mp4-65_jpg.rf.d933ce48947fa9bdb55dc702a0879ac9.jpg: 640x640 3 Safety Cones, 2 vehicles, 8.4ms\n",
            "image 33/82 /content/Construction-Site-Safety-28/test/images/autox_mp4-44_jpg.rf.5048603ee6ccedf9ae6e3f787b7f82ff.jpg: 640x640 2 NO-Safety Vests, 18 Safety Cones, 1 vehicle, 8.4ms\n",
            "image 34/82 /content/Construction-Site-Safety-28/test/images/bookstore_44_08_flickr_jpg.rf.244b6f308c529933af798c4063e58601.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 8.4ms\n",
            "image 35/82 /content/Construction-Site-Safety-28/test/images/class1_150_jpg.rf.5995dce34d38deb9eb0b6e36cae78f17.jpg: 640x640 1 Hardhat, 2 NO-Hardhats, 1 NO-Mask, 2 NO-Safety Vests, 2 Persons, 8.5ms\n",
            "image 36/82 /content/Construction-Site-Safety-28/test/images/class2_131_jpg.rf.ad8314a9273471f1280ce8789ea75376.jpg: 640x640 2 NO-Safety Vests, 1 Person, 8.3ms\n",
            "image 37/82 /content/Construction-Site-Safety-28/test/images/class2_145_jpg.rf.b8ed5a5357ee41f8fb1aa9b01a400d51.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 2 NO-Safety Vests, 2 Persons, 1 machinery, 8.3ms\n",
            "image 38/82 /content/Construction-Site-Safety-28/test/images/construction-1159-_jpg.rf.9f3172102a34edb157b556a73931c831.jpg: 640x640 1 machinery, 8.3ms\n",
            "image 39/82 /content/Construction-Site-Safety-28/test/images/construction-192-_jpg.rf.56dd5c4c1396c6ad01be4fbec3bca46f.jpg: 640x640 4 machinerys, 8.3ms\n",
            "image 40/82 /content/Construction-Site-Safety-28/test/images/construction-2-_mp4-13_jpg.rf.cef0975976346515d438e0c2ce6c59db.jpg: 640x640 3 machinerys, 8.3ms\n",
            "image 41/82 /content/Construction-Site-Safety-28/test/images/construction-2-_mp4-162_jpg.rf.efad5f15524c736fe03b9c9936adc481.jpg: 640x640 2 machinerys, 8.3ms\n",
            "image 42/82 /content/Construction-Site-Safety-28/test/images/construction-2-_mp4-84_jpg.rf.e8d6bb0acc5c6e82c1a2d260ddf3135e.jpg: 640x640 3 machinerys, 8.4ms\n",
            "image 43/82 /content/Construction-Site-Safety-28/test/images/construction-275-_jpg.rf.e1c57987f9dc262aad1d7c67b694fd87.jpg: 640x640 2 machinerys, 8.3ms\n",
            "image 44/82 /content/Construction-Site-Safety-28/test/images/construction-597-_jpg.rf.e18e918aae0aeecfdf8348513636d344.jpg: 640x640 2 machinerys, 8.3ms\n",
            "image 45/82 /content/Construction-Site-Safety-28/test/images/construction-639-_jpg.rf.7db2168ad99f643f7e3070733387e3bb.jpg: 640x640 1 machinery, 8.3ms\n",
            "image 46/82 /content/Construction-Site-Safety-28/test/images/construction-651-_jpg.rf.8fa283ce7693dbdf29eb98384f24cb85.jpg: 640x640 1 machinery, 8.5ms\n",
            "image 47/82 /content/Construction-Site-Safety-28/test/images/construction-675-_jpg.rf.bb4a05441be707256175e04929da3478.jpg: 640x640 1 Hardhat, 1 machinery, 8.4ms\n",
            "image 48/82 /content/Construction-Site-Safety-28/test/images/construction-800-_jpg.rf.a01fcddd0db9cc89c0cacf4af88c468d.jpg: 640x640 1 Person, 2 machinerys, 9.4ms\n",
            "image 49/82 /content/Construction-Site-Safety-28/test/images/construction-843-_jpg.rf.c0ca85a10f6ad3c1375b37e52a51eeed.jpg: 640x640 5 machinerys, 8.4ms\n",
            "image 50/82 /content/Construction-Site-Safety-28/test/images/image_53_jpg.rf.3446e366b5d4d905a32e1aedc8fe87de.jpg: 640x640 1 Hardhat, 1 Mask, 1 Person, 1 Safety Vest, 8.4ms\n",
            "image 51/82 /content/Construction-Site-Safety-28/test/images/image_55_jpg.rf.27ae4341a9b9647d73a8929ff7a22369.jpg: 640x640 1 Hardhat, 1 Mask, 1 Person, 1 Safety Vest, 8.4ms\n",
            "image 52/82 /content/Construction-Site-Safety-28/test/images/ka_01181_png_jpg.rf.154ee4ef254eabd62e316be50470c578.jpg: 640x640 1 Person, 6 Safety Cones, 1 vehicle, 8.5ms\n",
            "image 53/82 /content/Construction-Site-Safety-28/test/images/librairie_51_jpg.rf.56b0500ae2ad3820b4286133b627e59c.jpg: 640x640 (no detections), 8.5ms\n",
            "image 54/82 /content/Construction-Site-Safety-28/test/images/maksssksksss17_png_jpg.rf.f685b497756b1facbf3d4c2d2d22c0d2.jpg: 640x640 1 Mask, 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 8.4ms\n",
            "image 55/82 /content/Construction-Site-Safety-28/test/images/ppe_0018_jpg.rf.be66fabcc8627f60d963454b5a227095.jpg: 640x640 2 Hardhats, 3 NO-Masks, 2 Persons, 2 Safety Vests, 8.9ms\n",
            "image 56/82 /content/Construction-Site-Safety-28/test/images/ppe_1073_jpg.rf.72ea8a293a4f3e1135219e33701b1099.jpg: 640x640 9 Hardhats, 7 NO-Masks, 9 Persons, 8 Safety Vests, 8.4ms\n",
            "image 57/82 /content/Construction-Site-Safety-28/test/images/thumbnail-ba5c72edb320b49a69e86b05775c49b2-scaled-1_jpeg_jpg.rf.3bb460e284098219861b894fb0db13d5.jpg: 640x640 2 Hardhats, 7 Masks, 8 NO-Hardhats, 1 NO-Mask, 8 NO-Safety Vests, 14 Persons, 8.5ms\n",
            "image 58/82 /content/Construction-Site-Safety-28/test/images/youtube-108_jpg.rf.9dc7ed5f816f07d520f3dbfaad08d40f.jpg: 640x640 2 Hardhats, 1 NO-Hardhat, 2 NO-Masks, 2 Persons, 3 Safety Vests, 8.4ms\n",
            "image 59/82 /content/Construction-Site-Safety-28/test/images/youtube-114_jpg.rf.5e02b6574ace1f4b3689befbc5051cd0.jpg: 640x640 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 8.3ms\n",
            "image 60/82 /content/Construction-Site-Safety-28/test/images/youtube-126_jpg.rf.786824e90daf3276130ca73ca610a8da.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 2 Persons, 2 Safety Vests, 2 machinerys, 8.6ms\n",
            "image 61/82 /content/Construction-Site-Safety-28/test/images/youtube-152_jpg.rf.9147878e3ddda845e58f7d9c041f1338.jpg: 640x640 6 Persons, 7 machinerys, 2 vehicles, 8.5ms\n",
            "image 62/82 /content/Construction-Site-Safety-28/test/images/youtube-186_jpg.rf.1f1d93447d4be3233c22c4ce9f6e0601.jpg: 640x640 2 NO-Hardhats, 1 Person, 1 Safety Vest, 8.4ms\n",
            "image 63/82 /content/Construction-Site-Safety-28/test/images/youtube-192_jpg.rf.93bea040de8cd55f34ffb12f6ffe30b1.jpg: 640x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1 Safety Vest, 8.3ms\n",
            "image 64/82 /content/Construction-Site-Safety-28/test/images/youtube-198_jpg.rf.e89faeb9765c6bd6cece5434d140f4af.jpg: 640x640 2 Persons, 1 Safety Vest, 1 machinery, 8.3ms\n",
            "image 65/82 /content/Construction-Site-Safety-28/test/images/youtube-213_jpg.rf.da70b1d8cefd3cc9d56e43bb88dfb67d.jpg: 640x640 1 Hardhat, 1 NO-Hardhat, 2 Persons, 1 machinery, 8.7ms\n",
            "image 66/82 /content/Construction-Site-Safety-28/test/images/youtube-237_jpg.rf.d07a927721fe259757237c3706ea22e5.jpg: 640x640 1 Hardhat, 2 Persons, 1 machinery, 5 vehicles, 8.3ms\n",
            "image 67/82 /content/Construction-Site-Safety-28/test/images/youtube-253_jpg.rf.5ad0a2d701e20141940508b809584856.jpg: 640x640 (no detections), 8.7ms\n",
            "image 68/82 /content/Construction-Site-Safety-28/test/images/youtube-263_jpg.rf.374e343e12ead395440dbd81417e1be9.jpg: 640x640 2 Persons, 1 Safety Vest, 2 machinerys, 6 vehicles, 8.4ms\n",
            "image 69/82 /content/Construction-Site-Safety-28/test/images/youtube-263_jpg.rf.bb17b89dd2ec9a090ce53b728f48865e.jpg: 640x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 8.4ms\n",
            "image 70/82 /content/Construction-Site-Safety-28/test/images/youtube-34_jpg.rf.03eacc444bae3c5caa3fef5c736c3e40.jpg: 640x640 1 NO-Hardhat, 1 machinery, 1 vehicle, 8.3ms\n",
            "image 71/82 /content/Construction-Site-Safety-28/test/images/youtube-388_jpg.rf.18caa1da4f818a65f73e48463cb2270e.jpg: 640x640 3 machinerys, 8.3ms\n",
            "image 72/82 /content/Construction-Site-Safety-28/test/images/youtube-462_jpg.rf.df73aa5089a04b8fbf3adf9d614a6740.jpg: 640x640 3 Hardhats, 2 Persons, 2 Safety Vests, 1 vehicle, 8.3ms\n",
            "image 73/82 /content/Construction-Site-Safety-28/test/images/youtube-471_jpg.rf.4296b7bd9a5a07753077beddbcd651bf.jpg: 640x640 1 Person, 10.8ms\n",
            "image 74/82 /content/Construction-Site-Safety-28/test/images/youtube-472_jpg.rf.e9425ff40c0df2beeef70abbc2324956.jpg: 640x640 1 Person, 1 Safety Vest, 8.3ms\n",
            "image 75/82 /content/Construction-Site-Safety-28/test/images/youtube-496_jpg.rf.def4e9964e9a354d0a02f4ac14334a73.jpg: 640x640 (no detections), 8.3ms\n",
            "image 76/82 /content/Construction-Site-Safety-28/test/images/youtube-510_jpg.rf.62f82e36d134d53587edb48f291986f4.jpg: 640x640 (no detections), 8.2ms\n",
            "image 77/82 /content/Construction-Site-Safety-28/test/images/youtube-53_jpg.rf.e96f8f81389f4e63a79663095680a617.jpg: 640x640 1 Hardhat, 1 Person, 2 vehicles, 8.3ms\n",
            "image 78/82 /content/Construction-Site-Safety-28/test/images/youtube-596_jpg.rf.11a8a4ac01d8aadb80eeb0406dfa579a.jpg: 640x640 1 Mask, 2 NO-Safety Vests, 1 Person, 8.5ms\n",
            "image 79/82 /content/Construction-Site-Safety-28/test/images/youtube-631_jpg.rf.7c6ecf859c1b0a659f8ea057ad27aebd.jpg: 640x640 1 Hardhat, 1 Person, 1 Safety Vest, 8.3ms\n",
            "image 80/82 /content/Construction-Site-Safety-28/test/images/youtube-671_jpg.rf.7b08643d6754cabe6caf2b49a963de47.jpg: 640x640 (no detections), 8.3ms\n",
            "image 81/82 /content/Construction-Site-Safety-28/test/images/youtube-738_jpg.rf.6f300b76e12b325f7c373c95ef319005.jpg: 640x640 1 Hardhat, 1 Person, 4 Safety Vests, 8.7ms\n",
            "image 82/82 /content/Construction-Site-Safety-28/test/images/youtube-840_jpg.rf.974a83a7c5aee7c16e83435b043c6d96.jpg: 640x640 1 Hardhat, 3 NO-Masks, 1 Person, 1 Safety Vest, 1 machinery, 2 vehicles, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### get the test set performance"
      ],
      "metadata": {
        "id": "I6PNdqTXry3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changed the file name in order to use the validation function to find out test accurac\n",
        "# test changes to valid\n",
        "# valid change to valid1\n",
        "old_dir_path = '/content/Construction-Site-Safety-28/valid'\n",
        "new_dir_path = '/content/Construction-Site-Safety-28/valid1'\n",
        "\n",
        "# Rename the directory\n",
        "os.rename(old_dir_path, new_dir_path)\n",
        "\n",
        "old_dir_path_test = '/content/Construction-Site-Safety-28/test'\n",
        "new_dir_path_test = '/content/Construction-Site-Safety-28/valid'\n",
        "\n",
        "# Rename the directory\n",
        "os.rename(old_dir_path_test, new_dir_path_test)"
      ],
      "metadata": {
        "id": "lEmru7UqrsH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_transfer_n.val(data='/content/Construction-Site-Safety-28/data.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68-Lb-9prsFM",
        "outputId": "78953967-6470-4024-c5d4-825803be1606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.25 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Construction-Site-Safety-28/valid/labels.cache... 82 images, 8 backgrounds, 0 corrupt: 100%|██████████| 82/82 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 2/6 [00:00<00:00,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ NMS time limit 2.800s exceeded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:06<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         82        760      0.753      0.557      0.616      0.303\n",
            "               Hardhat         82        110      0.939      0.705      0.831      0.479\n",
            "                  Mask         82         28      0.895       0.61      0.733      0.357\n",
            "            NO-Hardhat         82         41      0.608      0.463      0.449      0.183\n",
            "               NO-Mask         82         79      0.702      0.544      0.541      0.183\n",
            "        NO-Safety Vest         82         90      0.786      0.456      0.584      0.265\n",
            "                Person         82        174       0.77      0.672      0.704      0.343\n",
            "           Safety Cone         82         92      0.683       0.38      0.392      0.151\n",
            "           Safety Vest         82         61      0.743      0.656      0.757      0.403\n",
            "             machinery         82         44      0.738       0.64       0.66      0.396\n",
            "               vehicle         82         41      0.668      0.441      0.505      0.274\n",
            "Speed: 0.2ms preprocess, 4.0ms inference, 0.0ms loss, 37.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7ab95ebec3a0>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0017128,  0.00085641,           0],\n",
              "       [          1,           1,           1, ...,  0.00033144,  0.00016572,           0],\n",
              "       [          1,           1,           1, ...,    0.000196,     9.8e-05,           0],\n",
              "       ...,\n",
              "       [          1,           1,           1, ...,   0.0013596,  0.00067981,           0],\n",
              "       [          1,           1,           1, ...,  0.00012204,  6.1022e-05,           0],\n",
              "       [          1,           1,           1, ...,  0.00028948,  0.00014474,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.16897,     0.16897,      0.2092, ...,           0,           0,           0],\n",
              "       [   0.057072,    0.057102,    0.093233, ...,           0,           0,           0],\n",
              "       [   0.059385,    0.059396,    0.086505, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [    0.10497,     0.10497,     0.13254, ...,           0,           0,           0],\n",
              "       [   0.021871,    0.021883,    0.035529, ...,           0,           0,           0],\n",
              "       [   0.067391,    0.067391,    0.093557, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.093333,    0.093333,     0.11851, ...,           1,           1,           1],\n",
              "       [   0.029563,    0.029579,    0.049421, ...,           1,           1,           1],\n",
              "       [   0.031042,    0.031048,    0.046177, ...,           1,           1,           1],\n",
              "       ...,\n",
              "       [   0.055666,    0.055666,    0.071428, ...,           1,           1,           1],\n",
              "       [   0.011084,     0.01109,    0.018159, ...,           1,           1,           1],\n",
              "       [   0.035267,    0.035267,    0.049864, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.89091,     0.89091,     0.89091, ...,           0,           0,           0],\n",
              "       [    0.82143,     0.82143,     0.82143, ...,           0,           0,           0],\n",
              "       [    0.68293,     0.68293,     0.68293, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [    0.91803,     0.91803,     0.91803, ...,           0,           0,           0],\n",
              "       [    0.81818,     0.81818,     0.81818, ...,           0,           0,           0],\n",
              "       [     0.7561,      0.7561,      0.7561, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.3345833454192557\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.47941,     0.35654,     0.18291,     0.18281,     0.26451,     0.34341,     0.15071,     0.40264,     0.39631,     0.27401])\n",
              "names: {0: 'Hardhat', 1: 'Mask', 2: 'NO-Hardhat', 3: 'NO-Mask', 4: 'NO-Safety Vest', 5: 'Person', 6: 'Safety Cone', 7: 'Safety Vest', 8: 'machinery', 9: 'vehicle'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.7531780239415288, 'metrics/recall(B)': 0.5567330731977653, 'metrics/mAP50(B)': 0.6159031931806888, 'metrics/mAP50-95(B)': 0.3033255845568742, 'fitness': 0.3345833454192557}\n",
              "save_dir: PosixPath('runs/detect/val')\n",
              "speed: {'preprocess': 0.1551087309674519, 'inference': 4.002379208076291, 'loss': 0.0007094406500095274, 'postprocess': 37.61795962729105}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interface"
      ],
      "metadata": {
        "id": "UqS_tEiADxeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, you can upload a random website picture to google drive"
      ],
      "metadata": {
        "id": "cBLtnUDnD4eD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# can be used if want to upload your own image and use the model to do object detection\n",
        "# ! pip install -q kaggle\n",
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "metadata": {
        "id": "EBLoXyJhD140"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the bounding box for this image"
      ],
      "metadata": {
        "id": "DoeS6g_p4Z16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_path = ### Change to google drive path\n",
        "\n",
        "# results = model_fine_n.predict(source=test_path, save=True)"
      ],
      "metadata": {
        "id": "kCG6SPUyF8bX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}